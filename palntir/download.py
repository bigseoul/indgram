"""
Palantir Foundry Dataset Downloader

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Palantir Foundryì—ì„œ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
Foundry REST APIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
"""

import os
import json
from pathlib import Path
import requests
import pandas as pd


def download_dataset(
    dataset_rid: str,
    output_path: str = None,
    output_format: str = "csv",
    foundry_token: str = None,
    foundry_hostname: str = None,
    branch: str = "master",
):
    """
    Palantir Foundryì—ì„œ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.

    Args:
        dataset_rid: Foundry ë°ì´í„°ì…‹ RID (ì˜ˆ: ri.foundry.main.dataset.xxx)
        output_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: í˜„ì¬ ë””ë ‰í† ë¦¬ì— dataset_rid.csv)
        output_format: ì¶œë ¥ í˜•ì‹ ('csv', 'parquet', 'json')
        foundry_token: Foundry API í† í° (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ FOUNDRY_TOKEN ì‚¬ìš©)
        foundry_hostname: Foundry í˜¸ìŠ¤íŠ¸ëª… (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ FOUNDRY_HOSTNAME ì‚¬ìš©)
        branch: ë°ì´í„°ì…‹ ë¸Œëœì¹˜ (ê¸°ë³¸ê°’: master)
    """
    # ì¸ì¦ ì •ë³´ ì„¤ì •
    # 1. íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬ëœ í† í° ì‚¬ìš©
    # 2. í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
    # 3. token.txt íŒŒì¼ì—ì„œ ì½ê¸°
    token = foundry_token or os.getenv("FOUNDRY_TOKEN")

    if not token:
        # token.txt íŒŒì¼ì´ ìˆìœ¼ë©´ ì½ê¸°
        token_file = Path(__file__).parent / "token.txt"
        if token_file.exists():
            token = token_file.read_text().strip()
            print("token.txt íŒŒì¼ì—ì„œ ì¸ì¦ í† í°ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")

    hostname = foundry_hostname or os.getenv(
        "FOUNDRY_HOSTNAME", "bigseoul.usw-22.palantirfoundry.com"
    )

    if not token:
        raise ValueError(
            "Foundry API í† í°ì´ í•„ìš”í•©ë‹ˆë‹¤. "
            "í™˜ê²½ë³€ìˆ˜ FOUNDRY_TOKENì„ ì„¤ì •í•˜ê±°ë‚˜ foundry_token íŒŒë¼ë¯¸í„°ë¥¼ ì œê³µí•˜ì„¸ìš”."
        )

    # ìš”ì²­ í—¤ë” ì„¤ì •
    headers = {
        "Authorization": f"Bearer {token}",
    }

    # ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
    print(f"Foundryì— ì—°ê²° ì¤‘... (hostname: {hostname})")
    print(f"ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘: {dataset_rid}")
    print(f"ë¸Œëœì¹˜: {branch}\n")

    try:
        # 1. Foundry REST APIë¡œ íŒŒì¼ ëª©ë¡ ì¡°íšŒ
        files_url = f"https://{hostname}/foundry-api/api/datasets/{dataset_rid}/branches/{branch}/files"
        print("íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì¤‘...")
        print(f"URL: {files_url}")

        # ì‹œë„í•  ë¸Œëœì¹˜ ëª©ë¡
        branches_to_try = [branch, "master", "main", "primary"]
        # ì¤‘ë³µ ì œê±°
        branches_to_try = list(dict.fromkeys(branches_to_try))

        # ì‹œë„í•  API ì—”ë“œí¬ì¸íŠ¸ íŒ¨í„´
        api_patterns = [
            "/foundry-api/api/datasets/{rid}/branches/{branch}/files",
            "/foundry-api/api/datasets/{rid}/files",
            "/api/v1/datasets/{rid}/branches/{branch}/files",
            "/api/v1/datasets/{rid}/files",
            "/catalog-api/api/datasets/{rid}/branches/{branch}/files",
        ]

        files_response = None
        successful_url = None
        successful_branch = None

        for branch_name in branches_to_try:
            if files_response and files_response.status_code == 200:
                break

            for pattern in api_patterns:
                # ë¸Œëœì¹˜ê°€ í•„ìš”í•œ íŒ¨í„´ì¸ì§€ í™•ì¸
                if "{branch}" in pattern:
                    files_url = f"https://{hostname}{pattern.format(rid=dataset_rid, branch=branch_name)}"
                else:
                    files_url = f"https://{hostname}{pattern.format(rid=dataset_rid)}"

                print(f"\nì‹œë„: {files_url}")

                try:
                    response = requests.get(files_url, headers=headers, timeout=30)

                    if response.status_code == 200:
                        files_response = response
                        successful_url = files_url
                        successful_branch = (
                            branch_name if "{branch}" in pattern else "N/A"
                        )
                        print("âœ… ì„±ê³µ!")
                        break
                    else:
                        print(f"âŒ ì‹¤íŒ¨ (ìƒíƒœ ì½”ë“œ: {response.status_code})")

                except Exception as e:
                    print(f"âŒ ì˜¤ë¥˜: {str(e)}")
                    continue

        if not files_response or files_response.status_code != 200:
            raise ValueError(
                f"ëª¨ë“  API ì—”ë“œí¬ì¸íŠ¸ì—ì„œ íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨\n\n"
                f"ì‹œë„í•œ ì—”ë“œí¬ì¸íŠ¸: {len(api_patterns) * len(branches_to_try)}ê°œ\n"
                f"ì‹œë„í•œ ë¸Œëœì¹˜: {', '.join(branches_to_try)}\n\n"
                f"ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:\n"
                f"1. ë°ì´í„°ì…‹ RIDê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸\n"
                f"2. í† í°ì— ë°ì´í„°ì…‹ ì½ê¸° ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸\n"
                f"3. hostnameì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸ ({hostname})\n"
                f"4. Foundry ì›¹ UIì—ì„œ ë¸Œëœì¹˜ëª… í™•ì¸\n"
                f"5. ë„¤íŠ¸ì›Œí¬/VPN ì—°ê²° í™•ì¸\n\n"
                f"ëŒ€ì•ˆ: MANUAL_DOWNLOAD.mdë¥¼ ì°¸ì¡°í•˜ì—¬ ì›¹ UIì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”."
            )

        print(f"\nâœ… ì„±ê³µí•œ ì—”ë“œí¬ì¸íŠ¸: {successful_url}")
        if successful_branch != "N/A":
            print(f"âœ… ì‚¬ìš©ëœ ë¸Œëœì¹˜: {successful_branch}")
            branch = successful_branch  # ì„±ê³µí•œ ë¸Œëœì¹˜ë¡œ ì—…ë°ì´íŠ¸

        files_data = files_response.json()

        # ì‘ë‹µ êµ¬ì¡° ë””ë²„ê¹…
        print("\nì‘ë‹µ êµ¬ì¡° í™•ì¸:")
        print(
            f"ì‘ë‹µ í‚¤: {list(files_data.keys()) if isinstance(files_data, dict) else 'Not a dict'}"
        )

        # ë‹¤ì–‘í•œ ì‘ë‹µ êµ¬ì¡° ì²˜ë¦¬
        files = []
        if isinstance(files_data, dict):
            if "files" in files_data:
                files = files_data["files"]
            elif "data" in files_data:
                files = files_data["data"]
            elif "values" in files_data:
                files = files_data["values"]
        elif isinstance(files_data, list):
            files = files_data

        if not files:
            print(f"ì‘ë‹µ ë‚´ìš© ìƒ˜í”Œ: {str(files_data)[:500]}")
            raise ValueError(
                "ë°ì´í„°ì…‹ì— íŒŒì¼ì´ ì—†ê±°ë‚˜ ì‘ë‹µ êµ¬ì¡°ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                "ìœ„ì˜ ì‘ë‹µ êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
            )

        # ë¡œê·¸ íŒŒì¼ ì œì™¸ (ì‹¤ì œ ë°ì´í„° íŒŒì¼ë§Œ)
        data_files = [f for f in files if not f.get("path", "").startswith("_/")]
        print(
            f"âœ“ íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì™„ë£Œ: {len(files)}ê°œ íŒŒì¼ (ë°ì´í„° íŒŒì¼: {len(data_files)}ê°œ)\n"
        )

        if not data_files:
            print("ê²½ê³ : ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  íŒŒì¼ë¡œ ì‹œë„í•©ë‹ˆë‹¤.")
            data_files = files

        # íŒŒì¼ ì •ë³´ ì¶œë ¥
        for i, file_info in enumerate(data_files[:10], 1):
            file_path = file_info.get("path", "")
            file_size = file_info.get("sizeInBytes", 0)
            print(f"  {i}. {file_path} ({file_size:,} bytes)")

        if len(data_files) > 10:
            print(f"  ... ì™¸ {len(data_files) - 10}ê°œ íŒŒì¼")

        # 2. íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        from io import BytesIO

        all_dataframes = []

        for idx, file_info in enumerate(data_files[:20]):  # ìµœëŒ€ 20ê°œ íŒŒì¼ ì²˜ë¦¬
            file_path = file_info.get("path")
            if not file_path:
                continue

            print(
                f"\níŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘ ({idx + 1}/{min(len(data_files), 20)}): {file_path}"
            )

            # ì—¬ëŸ¬ ë‹¤ìš´ë¡œë“œ URL íŒ¨í„´ ì‹œë„
            from urllib.parse import quote

            encoded_path = quote(file_path, safe="")

            download_patterns = [
                f"/api/v1/datasets/{dataset_rid}/files/{encoded_path}",
                f"/api/v1/datasets/{dataset_rid}/files/{file_path}",
                f"/foundry-api/api/datasets/{dataset_rid}/files/{file_path}/download",
                f"/foundry-api/api/datasets/{dataset_rid}/branches/{branch}/files/{file_path}/download",
                f"/catalog-api/datasets/{dataset_rid}/files/{file_path}",
            ]

            file_response = None
            for download_pattern in download_patterns:
                download_url = f"https://{hostname}{download_pattern}"

                try:
                    response = requests.get(download_url, headers=headers, timeout=180)

                    if response.status_code == 200:
                        file_response = response
                        print("  âœ… ë‹¤ìš´ë¡œë“œ ì„±ê³µ")
                        break

                except Exception:
                    continue

            if not file_response or file_response.status_code != 200:
                print("  âœ— ëª¨ë“  ë‹¤ìš´ë¡œë“œ URL ì‹¤íŒ¨")
                continue

            # íŒŒì¼ í¬ê¸° í™•ì¸
            file_size = len(file_response.content)
            print(f"  ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {file_size:,} bytes")

            # Content-Type í™•ì¸
            content_type = file_response.headers.get("Content-Type", "unknown")

            # JSON ì‘ë‹µì¸ ê²½ìš° ë©”íƒ€ë°ì´í„°ì¼ ìˆ˜ ìˆìŒ
            if "json" in content_type.lower() or file_size < 1000:
                try:
                    metadata = json.loads(file_response.content)
                    if isinstance(metadata, dict) and "sizeBytes" in metadata:
                        print(
                            f"  â„¹ï¸  ë©”íƒ€ë°ì´í„° ì‘ë‹µ ê°ì§€ (ì‹¤ì œ í¬ê¸°: {metadata.get('sizeBytes')} bytes)"
                        )
                        print("  âš ï¸  ì‹¤ì œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

                        # transactionRidë¥¼ ì‚¬ìš©í•œ ë‹¤ìš´ë¡œë“œ ì‹œë„
                        transaction_rid = metadata.get("transactionRid")
                        if transaction_rid:
                            print("  ğŸ”„ transactionRidë¥¼ ì‚¬ìš©í•˜ì—¬ ì¬ì‹œë„...")
                            # ì¶”ê°€ ì‹œë„í•  ìˆ˜ ìˆëŠ” ë‹¤ë¥¸ íŒ¨í„´ë“¤
                            continue
                except:
                    pass

            # íŒŒì¼ í˜•ì‹ì— ë”°ë¼ íŒŒì‹±
            try:
                # Parquet íŒŒì¼ ì‹œë„
                if file_path.endswith(".parquet") or file_path.endswith(
                    ".snappy.parquet"
                ):
                    df_chunk = pd.read_parquet(BytesIO(file_response.content))
                    all_dataframes.append(df_chunk)
                    print(
                        f"  âœ“ Parquet íŒŒì‹± ì„±ê³µ: {len(df_chunk):,} í–‰, {len(df_chunk.columns)} ì—´"
                    )
                # CSV íŒŒì¼ ì‹œë„
                elif file_path.endswith(".csv"):
                    df_chunk = pd.read_csv(BytesIO(file_response.content))
                    all_dataframes.append(df_chunk)
                    print(
                        f"  âœ“ CSV íŒŒì‹± ì„±ê³µ: {len(df_chunk):,} í–‰, {len(df_chunk.columns)} ì—´"
                    )
                else:
                    # í™•ì¥ì ì—†ëŠ” ê²½ìš° parquet ë¨¼ì € ì‹œë„
                    try:
                        df_chunk = pd.read_parquet(BytesIO(file_response.content))
                        all_dataframes.append(df_chunk)
                        print(
                            f"  âœ“ Parquet íŒŒì‹± ì„±ê³µ: {len(df_chunk):,} í–‰, {len(df_chunk.columns)} ì—´"
                        )
                    except Exception:
                        # CSVë¡œ ì¬ì‹œë„
                        df_chunk = pd.read_csv(BytesIO(file_response.content))
                        all_dataframes.append(df_chunk)
                        print(
                            f"  âœ“ CSV íŒŒì‹± ì„±ê³µ: {len(df_chunk):,} í–‰, {len(df_chunk.columns)} ì—´"
                        )

            except Exception as e:
                print(f"  âœ— íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
                continue

        if not all_dataframes:
            raise ValueError("ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # ëª¨ë“  ë°ì´í„°í”„ë ˆì„ ë³‘í•©
        if len(all_dataframes) == 1:
            df = all_dataframes[0]
        else:
            print(f"\n{len(all_dataframes)}ê°œ íŒŒì¼ ë³‘í•© ì¤‘...")
            df = pd.concat(all_dataframes, ignore_index=True)

        print(f"\nâœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(df):,} í–‰, {len(df.columns)} ì—´")
        print(f"ì»¬ëŸ¼: {list(df.columns)}")

        # ì¶œë ¥ ê²½ë¡œ ì„¤ì •
        if output_path is None:
            dataset_name = dataset_rid.split(".")[-1]
            output_path = f"{dataset_name}.{output_format}"

        # ë°ì´í„° ì €ì¥
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        if output_format == "csv":
            df.to_csv(output_path, index=False, encoding="utf-8-sig")
        elif output_format == "parquet":
            df.to_parquet(output_path, index=False)
        elif output_format == "json":
            df.to_json(output_path, orient="records", force_ascii=False, indent=2)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {output_format}")

        print(f"ì €ì¥ ì™„ë£Œ: {output_path.absolute()}\n")
        return df

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ë‹¤ìš´ë¡œë“œí•  ë°ì´í„°ì…‹ RID
    DATASET_RID = "ri.foundry.main.dataset.a60255aa-23e1-41ce-a0f0-448337578971"

    # ì €ì¥í•  ê²½ë¡œ (í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€)
    output_dir = Path(__file__).parent / "data"
    output_file = output_dir / "downloaded_dataset.csv"

    try:
        df = download_dataset(
            dataset_rid=DATASET_RID,
            output_path=str(output_file),
            output_format="csv",
        )

        # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
        print("=== ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ===")
        print(df.head(10))
        print(f"\në°ì´í„° í˜•íƒœ: {df.shape}")
        print(f"\në°ì´í„° íƒ€ì…:\n{df.dtypes}")

    except Exception as e:
        print(f"\në‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        print("\nì„¤ì • í™•ì¸ì‚¬í•­:")
        print("1. FOUNDRY_TOKEN í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸")
        print("2. FOUNDRY_HOSTNAME í™˜ê²½ë³€ìˆ˜ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
        print("3. ë°ì´í„°ì…‹ RIDê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
        print("4. ë°ì´í„°ì…‹ì— ëŒ€í•œ ì½ê¸° ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸")


if __name__ == "__main__":
    main()
